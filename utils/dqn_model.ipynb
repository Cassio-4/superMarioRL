{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLpSj57jWcpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KOfdinbWzoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Para implementarmos nossa rede de maneira genérica, esta foi implementada em \n",
        "duas partes: de convolução e sequencial. PyTorch não tem uma camada de 'flatter'\n",
        "que serve para transformar um tensor 3D em um array 1D de números, necessário\n",
        "para alimentar a saída da camada de convolução para a camada totalmente conecta-\n",
        "-da (fully conected layer). Este problema e resolvido no método forward(), onde\n",
        "podemos redimensionar nosso 'batch' de tensores 3D em um 'batch' de vetores 1D\n",
        "\"\"\"\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        conv_out_size = self._get_conv_out(input_shape)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "    \"\"\"\n",
        "    Outro problema é que não sabemos o número exato de valores na saída da\n",
        "    camada de convolução produzidos a partir do input com dado formato (shape). \n",
        "    Entretanto precisamos passar esse número para o construtor da primeira cama-\n",
        "    -da totalmente conectada. A função _get_conv_out() aceita o formato de entrada\n",
        "    e aplica a camada de convoluçao em um tensor falso de tal formato. O resultado\n",
        "    da função será igual ao número de parametros retornados por essa aplicação.\n",
        "    Sera rápido, visto que essa chamada só ocorre uma vez na criação do modelo,\n",
        "    mas permitirá que nosso código seja genérico.\n",
        "    \"\"\"\n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "    \"\"\"\n",
        "    A função forward() aceita o tensor de entrada 4D (a primeira dimensão é o \n",
        "    tamanho da batch, a segunda é o canal de cor e a terceira e quarta são as \n",
        "    dimensões da imagem). Primeiro aplicamos a camada de convolução para a entrada\n",
        "    e então obtemos um tensor 4D de saída. Este resultado é então 'flattened' para\n",
        "    ter duas dimensões: o tamanho da batch e todos os parâmetros retornados pela\n",
        "    convolução para essa batch como um longo vetor de números.\n",
        "    \"\"\"\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
        "        return self.fc(conv_out)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}